{
    "cells": [
        {
            "cell_type": "code",
            "metadata": {
                "language": "python"
            },
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "from scipy.stats import multivariate_normal\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Set reproducibility\n",
                "np.random.seed(42)\n",
                "\n",
                "# Simulation parameters\n",
                "N_total = 1000000       # total population\n",
                "N_train = 800000       # training cohort\n",
                "N_test = N_total - N_train\n",
                "D = 6                # number of variables\n",
                "bins_list = [4, 8, 16, 36, 64, 128]  # discretization levels\n",
                "\n",
                "# Generate correlated multivariate data\n",
                "mu = np.zeros(D)\n",
                "Sigma = 0.5 * np.ones((D, D)) + 0.5 * np.eye(D)  # correlated structure\n",
                "latent = np.random.multivariate_normal(mu, Sigma, size=N_total)\n",
                "\n",
                "# Split train/test\n",
                "latent_train = latent[:N_train]\n",
                "latent_test  = latent[N_train:]\n",
                "\n",
                "# Assume the first variable is the clinical outcome\n",
                "clinical_outcome = latent[:, 0]\n",
                "\n",
                "def quantile_discretize(arr, bins):\n",
                "    \"\"\"Discretize each column into equal-frequency quantile bins.\"\"\"\n",
                "    arr_disc = np.zeros_like(arr, dtype=int)\n",
                "    for j in range(arr.shape[1]):\n",
                "        ranks = arr[:, j].argsort().argsort()\n",
                "        arr_disc[:, j] = np.ceil((ranks + 1) / len(ranks) * bins).astype(int)\n",
                "        arr_disc[arr_disc[:, j] > bins, j] = bins\n",
                "    return arr_disc\n",
                "\n",
                "def identify_accuracy(train, test, bins):\n",
                "    \"\"\"Estimate identifiability for given discretization.\"\"\"\n",
                "    mu_hat = train.mean(axis=0)\n",
                "    Sigma_hat = np.cov(train, rowvar=False)\n",
                "    inv_Sigma = np.linalg.pinv(Sigma_hat)\n",
                "    \n",
                "    correct = 0\n",
                "    known_var = 0  # assume we only know variable 0 for reidentification\n",
                "\n",
                "    for i, x in enumerate(test):\n",
                "        x_obs = x[known_var]\n",
                "        likelihoods = []\n",
                "        for j, candidate in enumerate(test):\n",
                "            diff = candidate - mu_hat\n",
                "            mdist = diff @ inv_Sigma @ diff.T\n",
                "            likelihoods.append(-mdist)\n",
                "        guess = np.argmax(likelihoods)\n",
                "        if guess == i:\n",
                "            correct += 1\n",
                "    return correct / len(test)\n",
                "\n",
                "# Run for each discretization level\n",
                "results = []\n",
                "for bins in bins_list:\n",
                "    print(f\"\\n=== Evaluating discretization with {bins} bins ===\")\n",
                "    disc = quantile_discretize(latent, bins)\n",
                "    train_disc = disc[:N_train]\n",
                "    test_disc  = disc[N_train:]\n",
                "    acc = identify_accuracy(train_disc, test_disc, bins)\n",
                "    print(f\"Identifiability (Top-1 Accuracy): {acc*100:.2f}%\")\n",
                "    results.append((bins, acc))\n",
                "\n",
                "df = pd.DataFrame(results, columns=[\"Discretization_bins\", \"Identifiability\"])\n",
                "print(df)"
            ]
        }
    ]
}